{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c1b328-3929-4915-8efe-c5ccc2c20ff9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd84c5-bffb-4fe1-9a1c-f13bf06d8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebirdtools import EBirdTools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6b051-1d1c-4de0-afbd-e1ebb0a5014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_label(path):\n",
    "    \"\"\"\n",
    "    Reads a data file into a df, normalizes elevation data, and labels\n",
    "    with a new column specifying which cluster each row belongs to.\n",
    "    \"\"\"\n",
    "    df = EBirdTools.load_data(path)\n",
    "    df['ele'] = df['elevation_meters'].apply(lambda x: x/1000)\n",
    "    \n",
    "    clustering = KMeans(n_clusters=round(len(df) ** (1/3))).fit(df[['lat', 'lng', 'ele']])\n",
    "    df['cluster'] = pd.Series(clustering.labels_, index=df.index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5bde2-8589-4700-ae98-b4cbf1821c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose    = load_and_label('data/ebd_alt_2025-08-20-20-26-00_37.33_-121.86_30_50.csv')\n",
    "losangeles = load_and_label('data/ebd_alt_2025-08-20-20-40-54_34.05_-118.24_30_50.csv')\n",
    "seattle    = load_and_label('data/ebd_alt_2025-08-20-20-44-54_47.61_-122.33_30_50.csv')\n",
    "chicago    = load_and_label('data/ebd_alt_2025-08-20-20-35-54_41.88_-87.63_30_50.csv')\n",
    "everglades = load_and_label('data/ebd_alt_2025-08-20-20-31-45_25.75_-80.56_30_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7aacc-70d9-4cc5-abde-84d01d39347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(df, frac=0.1, cluster=None):\n",
    "    \"\"\"\n",
    "    Shows interactive map of sightings. Has option to show only\n",
    "    points from the specified cluster.\n",
    "    \"\"\"\n",
    "    if cluster is not None:\n",
    "        df = df.copy()\n",
    "        df = df[df['cluster'] == cluster]\n",
    "    df = df.copy().sample(frac=frac)  # reduces memory load\n",
    "    fig = px.scatter_mapbox(df, lat='lat', lon='lng', color='cluster', hover_name='comName')\n",
    "    fig.update_mapboxes(style='open-street-map')\n",
    "    fig.show()\n",
    "    \n",
    "def cluster_hist(df):\n",
    "    \"\"\"\n",
    "    Shows a histogram of cluster sizes.\n",
    "    \"\"\"\n",
    "    df['cluster'].value_counts().plot.hist()\n",
    "\n",
    "def get_exclusive_species(df_src, df_tgt):\n",
    "    \"\"\"\n",
    "    Returns the set of species found in the source df\n",
    "    that are not found in the target df.\n",
    "    \"\"\"\n",
    "    spec_src = set(df_src['comName'].values)\n",
    "    spec_tgt = set(df_tgt['comName'].values)\n",
    "    exclusive = spec_src.difference(spec_tgt)\n",
    "    return exclusive\n",
    "\n",
    "def get_intersecting_species(df_src, df_tgt):\n",
    "    \"\"\"\n",
    "    Returns the set of species found in both df.\n",
    "    \"\"\"\n",
    "    spec_src = set(df_src['comName'].values)\n",
    "    spec_tgt = set(df_tgt['comName'].values)\n",
    "    intersect = spec_src.intersection(spec_tgt)\n",
    "    return intersect\n",
    "\n",
    "def species_per_cluster(df, by='comName'):\n",
    "    \"\"\"\n",
    "    Takes a df and returns a dict:\n",
    "        Key: Cluster number\n",
    "        Val: set of names found in the cluster\n",
    "    \"\"\"\n",
    "    species = {}\n",
    "    for i in pd.unique(df['cluster']):\n",
    "        names = set(df[df['cluster'] == i][by])\n",
    "        species[i] = names\n",
    "    return species\n",
    "\n",
    "def get_similarity(df_a, df_b, hist=False):\n",
    "    \"\"\"\n",
    "    Gets cluster similarity by calculating the set similarity\n",
    "    (intersection over union) of the species names found in\n",
    "    each cluster.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    sp_a = species_per_cluster(df_a)\n",
    "    sp_b = species_per_cluster(df_b)\n",
    "    for k_a, v_a in sp_a.items():\n",
    "        for k_b, v_b in sp_b.items():\n",
    "            iou = len(v_a.intersection(v_b)) / len(v_a.union(v_b))\n",
    "            d = {'A': k_a, 'B': k_b, 'iou': iou}\n",
    "            output.append(d)\n",
    "\n",
    "    output = pd.DataFrame(output).sort_values('iou')\n",
    "    if hist:\n",
    "        output['iou'].plot.hist()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbc9f6-6c41-47b9-b31d-8bb709408b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(name, df_src, df_tgt):\n",
    "    if name not in df_src['comName'].values:\n",
    "        raise KeyError('Unable to find species in the source region.')\n",
    "    print('Is bird already found in the target region?', name in df_tgt['comName'].values)\n",
    "    \n",
    "    # find which source clusters the named species occurs in\n",
    "    src_clusters = np.unique(df_src[df_src['comName'] == name]['cluster'])\n",
    "    # drop the clusters that the named species doesn't occur in\n",
    "    df_srcdrop = df_src[df_src['cluster'].isin(src_clusters)]\n",
    "    # compare species sets\n",
    "    sims = get_similarity(df_srcdrop, df_tgt)\n",
    "    \n",
    "    s_mean = sims['iou'].mean()\n",
    "    s_std = sims['iou'].std()\n",
    "    s_max = sims['iou'].max()\n",
    "    s_z = (s_max - s_mean) / s_std\n",
    "    a = sims[sims['iou'] == s_max]['A'].item()\n",
    "    b = sims[sims['iou'] == s_max]['B'].item()\n",
    "    print('Sub-cluster compatability:', round(s_mean, 2))\n",
    "    print('Highest similarity:', round(s_max, 2), f'(z {round(s_z, 2)})')\n",
    "\n",
    "    sightings_a = df_src['cluster'].value_counts()\n",
    "    sa_mean = sightings_a.mean()\n",
    "    sa_std = sightings_a.std()\n",
    "    sa_z = (sightings_a[a] - sa_mean) / sa_std\n",
    "    print('Source cluster:', a, f'(num sightings z {round(sa_z, 2)})')\n",
    "    sightings_b = df_tgt['cluster'].value_counts()\n",
    "    sb_mean = sightings_b.mean()\n",
    "    sb_std = sightings_b.std()\n",
    "    sb_z = (sightings_b[b] - sb_mean) / sb_std\n",
    "    print('Target cluster:', b, f'(num sightings z {round(sb_z, 2)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b928b5-7edf-43cd-b6f6-563f15ecb4b4",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7d853-6c00-4478-b81d-a3ebb90d5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (losangeles, everglades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f1ea7-00c6-402b-83bd-b09651d897c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(data[0])\n",
    "cluster_hist(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4858e0-e0e2-459b-b2e2-ebb21acbead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(data[1])\n",
    "cluster_hist(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb217d-bbbd-42c3-b497-27a4ed2fa5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity(*data, hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c73d5-5144-4ca5-8235-68d580b3dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_intersecting_species(*data)\n",
    "get_exclusive_species(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d04276-dff7-4ec3-bc7f-fd9e1dbfe530",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze('American Avocet', *data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bbe6b-781c-4521-8711-9865b9e11701",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(data[0], cluster=)\n",
    "plot_map(data[1], cluster=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7eba9-24b4-4380-9b62-3f4e932d1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze('Pygmy Nuthatch', *data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efc470-7cb9-477a-848b-b4746d27b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(data[0], cluster=)\n",
    "plot_map(data[1], cluster=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
